# Сводка изменений: Упрощение архитектуры бота

## Что изменилось

Убрана сложная RAG (Retrieval-Augmented Generation) система в пользу простого подхода с использованием последних 100 сообщений для контекста.

## Удаленные компоненты

### Файлы:
- `internal/rag/` - вся папка с RAG функциональностью
- `docs/rag.md` - документация по RAG системе
- `CHANGELOG_RAG.md` - предыдущий changelog по RAG

### Методы и функции:
- `llm.Client.GenerateResponseWithRAG()` - метод для генерации с RAG
- `llm.Client.buildChatContextWithRAG()` - построение контекста с RAG
- `repository.SearchRelevantMessages()` - поиск релевантных сообщений
- `config.RAGMaxRelevantMessages` - настройка максимального количества релевантных сообщений
- `config.RAGRecentDaysExclude` - настройка исключения недавних дней
- `models.MessageDocument.Score` - поле для хранения релевантности

## Добавленные компоненты

### Новые методы:
- `repository.GetLastMessages(chatID, limit)` - получение последних N сообщений

## Новая логика работы

1. При получении сообщения бот загружает последние 100 сообщений из чата
2. Использует их как контекст для LLM
3. Генерирует ответ с помощью `llm.Client.GenerateResponse()`

## Преимущества упрощения

- ✅ Простота кода и архитектуры
- ✅ Меньше зависимостей
- ✅ Быстрая загрузка контекста без сложных поисковых запросов
- ✅ Предсказуемое поведение

## Обновленная конфигурация

Из `.env.example` удалены:
```bash
RAG_MAX_RELEVANT_MESSAGES=5
RAG_RECENT_DAYS_EXCLUDE=3
```

Теперь для работы достаточно основных настроек MongoDB и LLM API.
